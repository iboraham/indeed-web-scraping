{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read cv file (pdf or txt)\n",
    "with open('cv/cv.txt','rb') as file:\n",
    "    cv = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>OSTC</td>\n",
       "      <td>Company Description\\nIn just over 15 years, OS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Biostatistician / Data Scientist - Innovative ...</td>\n",
       "      <td>Warman O'Brien</td>\n",
       "      <td>Biostatistician / Data Scientist - London\\nI a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ctrlio Ltd</td>\n",
       "      <td>ctrlio helps motor insurers win customers more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Novafutur</td>\n",
       "      <td>This is an opportunity to become a Data Scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Data Scientist Lead</td>\n",
       "      <td>JPMorgan Chase Bank, N.A.</td>\n",
       "      <td>Position Overview &amp; Responsibilities:\\nThis is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                     Data Scientist   \n",
       "1  Biostatistician / Data Scientist - Innovative ...   \n",
       "2                                     Data Scientist   \n",
       "3                              Junior Data Scientist   \n",
       "4                                Data Scientist Lead   \n",
       "\n",
       "                     Company  \\\n",
       "0                       OSTC   \n",
       "1             Warman O'Brien   \n",
       "2                 ctrlio Ltd   \n",
       "3                  Novafutur   \n",
       "4  JPMorgan Chase Bank, N.A.   \n",
       "\n",
       "                                         Description  \n",
       "0  Company Description\\nIn just over 15 years, OS...  \n",
       "1  Biostatistician / Data Scientist - London\\nI a...  \n",
       "2  ctrlio helps motor insurers win customers more...  \n",
       "3  This is an opportunity to become a Data Scient...  \n",
       "4  Position Overview & Responsibilities:\\nThis is...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read d.scientist csv\n",
    "ds = pd.read_csv('jobs data/data_scientist.csv')\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Machine Learning Engineer Graduate Scheme</td>\n",
       "      <td>Kubrick Group</td>\n",
       "      <td>Would you love to explore a career in Data Sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Machine Learning Engineer-Trust &amp; Safety</td>\n",
       "      <td>TikTok</td>\n",
       "      <td>Responsibilities\\nTikTok is the leading destin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Engineer, Machine Learning</td>\n",
       "      <td>OakNorth Bank</td>\n",
       "      <td>OakNorth is the next-generation credit and mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Machine Learning Research Engineer</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Who we are\\nAre you interested in helping buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CIB Applied AI &amp; Machine Learning - Economic a...</td>\n",
       "      <td>JPMorgan Chase Bank, N.A.</td>\n",
       "      <td>About Data Analytics within Global Research\\nD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0          Machine Learning Engineer Graduate Scheme   \n",
       "1           Machine Learning Engineer-Trust & Safety   \n",
       "2                         Engineer, Machine Learning   \n",
       "3                 Machine Learning Research Engineer   \n",
       "4  CIB Applied AI & Machine Learning - Economic a...   \n",
       "\n",
       "                     Company  \\\n",
       "0              Kubrick Group   \n",
       "1                     TikTok   \n",
       "2              OakNorth Bank   \n",
       "3                    Twitter   \n",
       "4  JPMorgan Chase Bank, N.A.   \n",
       "\n",
       "                                         Description  \n",
       "0  Would you love to explore a career in Data Sci...  \n",
       "1  Responsibilities\\nTikTok is the leading destin...  \n",
       "2  OakNorth is the next-generation credit and mon...  \n",
       "3  Who we are\\nAre you interested in helping buil...  \n",
       "4  About Data Analytics within Global Research\\nD...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read m.learning engineers csv\n",
    "ml = pd.read_csv('jobs data/ml.csv')\n",
    "ml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get desc of the jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34.72222222222222, 30.73170731707317)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trim skills and reqs from desc of jobs\n",
    "def empty_count(str_series):\n",
    "    counter = 0\n",
    "    for ind in str_series:\n",
    "        if ind == []:\n",
    "            counter+=1\n",
    "    return counter\n",
    "ds_desc=ds.Description.str.lower()\n",
    "ml_desc=ml.Description.str.lower()\n",
    "ds_qualifs=ds_desc.str.findall(r'((?:qualifications|requirements|desirable|skills|required|role)+(?:\\:|\\?|\\n)(?:.|\\s)*)')\n",
    "ml_qualifs=ml_desc.str.findall(r'((?:qualifications|requirements|desirable|skills|required|role)+(?:\\:|\\?|\\n)(?:.|\\s)*)')\n",
    "empty_count(ml_qualifs)/len(ml_qualifs)*100, empty_count(ds_qualifs)/len(ds_qualifs)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat\n",
    "ml_desc_ready=ml_desc.str.cat(sep=';;;')\n",
    "ds_desc_ready=ds_desc.str.cat(sep=';;;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate similarity between cv and jobs desc's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bibrahim onur serbetcinprofilenindustrial engineering major 304 gpa currently attending mef university 10 months work experience aiming leverage proven knowledge advanced technology machine learning optimization statistics skills successfully data scientist frequently praised hard working peers relied upon help company achieve goalsrhard skillsnrn constructing predictive models pythonn data analysisn machine learningn javan statistical analysisn data wranglingn sqln microsoft officencontactnmobile 90 5370173333 ionurserbetcigmailcom 123 ince kas street istanbul linkedin ionurserbetcinreferencesnsoft skillsn analytical thinking presentation critical thinking creativity communication collaborationr references avaliable upon requestrwork experxc4xb0encenoperations internnsanko holding jun 2019 jul 2019n support review production schedules engineering specifications orders related information obtain knowledge manufacturing methods procedures activitiesn estimate production costs costsaving methods effects product design changes expenditures management review action controlnerp developer internnacrome robotics oct 2018 dec 2018n carrying product classification coding processes production systems teamn create amazon aws ec2 instance company n strengthening odoo erp system used company developing new odoo environmentnfinancial business analysis intern volkswagen financial services aug 2018 sep 2018n supporting evaluation processing credit truck bus vdf credit assessment departmentn supporting financial analysis making process companies credit applicationsn systematizing archiving credit application contracts help register vdfnet systemn supporting credit configuration processnsupply chain efficiency internnbsh home appliances group jun 2018 aug 2018n supporting prepare production plans oven factory assembly lines support international logistics procurement processes using sap pp sap mmn support preparing reports logistics performance measuresn provide ongoing analyses areas transportation costs parts procurement backorders delivery processesneducationnmef universitynbachelor science industrial engineeringn years attended 2015 2020n member ieeen coursework probability statistics iii introduction machine learning operations research iii marketing analytics explanatory data analytics information systems modeling methods optimization decision analysis business intelligencen honor degree spring 20162017 spring 20172018 fall 20192020n gpa 304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfrom nltk.stem.porter import *\\nfrom collections import Counter\\nstemmer = PorterStemmer()\\nds_stemmed = []\\nfor item in ds_filtered:\\n    ds_stemmed.append(stemmer.stem(item))\\nml_stemmed = []\\nfor item in ml_filtered:\\n    ml_stemmed.append(stemmer.stem(item))\\nds = ' '.join([el[0] for el in Counter(ds_stemmed).most_common(200)])\\nml = ' '.join([el[0] for el in Counter(ml_stemmed).most_common(200)])\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make a text corpus containing all words of documents. Use tokenisation and stop word removal.\n",
    "import string\n",
    "ds_lowers = ds_desc_ready.lower()\n",
    "ml_lowers = ml_desc_ready.lower()\n",
    "cv_lowers = cv.lower()\n",
    "cv_lowers = str(cv_lowers)\n",
    "\n",
    "#punctuation\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "ds_clean = ds_lowers.translate(translator)\n",
    "ml_clean = ml_lowers.translate(translator)\n",
    "cv_clean = cv_lowers.translate(translator)\n",
    "\n",
    "#tokenize\n",
    "ds_tokens = nltk.word_tokenize(ds_clean)\n",
    "ml_tokens = nltk.word_tokenize(ml_clean)\n",
    "cv_tokens = nltk.word_tokenize(cv_clean)\n",
    "\n",
    "\n",
    "# Use stopwords\n",
    "from nltk.corpus import stopwords\n",
    "ds_filtered = [w for w in ds_tokens if not w in stopwords.words('english')]\n",
    "ml_filtered = [w for w in ml_tokens if not w in stopwords.words('english')]\n",
    "cv_filtered = [w for w in cv_tokens if not w in stopwords.words('english')]\n",
    "ds = ' '.join(ds_filtered)\n",
    "ml = ' '.join(ml_filtered)\n",
    "cv = ' '.join(cv_filtered)\n",
    "print(cv)\n",
    "\n",
    "\n",
    "#Stemming is optional\n",
    "'''\n",
    "from nltk.stem.porter import *\n",
    "from collections import Counter\n",
    "stemmer = PorterStemmer()\n",
    "ds_stemmed = []\n",
    "for item in ds_filtered:\n",
    "    ds_stemmed.append(stemmer.stem(item))\n",
    "ml_stemmed = []\n",
    "for item in ml_filtered:\n",
    "    ml_stemmed.append(stemmer.stem(item))\n",
    "ds = ' '.join([el[0] for el in Counter(ds_stemmed).most_common(200)])\n",
    "ml = ' '.join([el[0] for el in Counter(ml_stemmed).most_common(200)])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the documents into tf-idf vectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "docs = [ds,ml,cv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the cosine-similarity between them or any new document for similarity measure.\n",
    "tfidf = vect.fit_transform(docs)\n",
    "similarity = tfidf*tfidf.T\n",
    "similarity=similarity.toarray()\n",
    "\n",
    "#another method\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_sim = cosine_similarity(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>ml</th>\n",
       "      <th>cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ds</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.859783</td>\n",
       "      <td>0.276385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ml</td>\n",
       "      <td>0.859783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.254288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cv</td>\n",
       "      <td>0.276385</td>\n",
       "      <td>0.254288</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds        ml        cv\n",
       "ds  1.000000  0.859783  0.276385\n",
       "ml  0.859783  1.000000  0.254288\n",
       "cv  0.276385  0.254288  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_name = ['ds','ml','cv']\n",
    "results = pd.DataFrame(data=similarity,index=docs_name,columns=docs_name)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As a result, I should improve my resume for these fields."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
